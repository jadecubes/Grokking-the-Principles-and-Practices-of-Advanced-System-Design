# Design Refinements in MapReduce: Part II
We can incorporate the following refinements to get insights into our system’s status and performance, along with error handling mechanisms and debugging facilities. All of these refinements are supplementary to the previously covered refinements and augment the overall efficiency of the design.

## Status information
Even with all the distribution and parallelization, the MapReduce job is a time-taking process. For example, the best Hadoop (an open source implementation of Google’s MapReduce library) performance to date for processing 102.5 TB data is 4,328 seconds (1.2 hours), achieved by Thomas Graves of Yahoo! Inc. He used the following configuration for this task: 2100 nodes (each node had: 2 2.3Ghz hex-core Xeon E5-2630, 64 GB memory, 12x3TB disks).
```
Source: sortbenchmark.org
```

It’s beneficial for the users to access the status of their MapReduce jobs to get insights and make crucial decisions in case any modifications are required.


### Status pages
The master houses an internal HTTP server and provides users access to a set of status pages. These status pages present the computation progress, such as the number of completed tasks, the number of in-progress tasks, input data size, intermediate data size, output data size, processing rates, etc.

These pages also contain information about the number of failed tasks, the workers they were running on, and which Map or Reduce tasks they were processing, along with links to the standard errors.

These status pages also provide users with links to the standard output files generated by each task.

[Status page access via an HTTP server]

Users can analyze this data to infer the following information:

- How long the computation will take
- Whether or not there more resources need to be added to the computation
- The individual processing rates of workers

## Counters
The MapReduce library has an in-built facility to compute the counters of various events. It houses some counters by default, like the number of processed input and generated output key-value pairs.

In addition to these default counters, users can define a customized counter by creating a counter object in the user code and incrementing it appropriately in the Map or Reduce functions.

#### Examples
The user might need the number of processed words or the number of indexed German documents.

### Process of accumulating the counter output
Each worker houses a local counter object and periodically sends the value to the master by piggybacking it on the ping response. The master aggregates the individual counter values from successful Map and Reduce tasks and returns the accumulated value upon MapReduce job completion.

[The master accumulates the counter values from individual workers]

When aggregating the counter values, the master avoids double counting by eliminating the effects of double execution, which might result from backup tasks or re-execution in case of failures.
```
Note: The users can also see the current counter value by accessing the master’s status page.
```
### Applying the counters
## Skipping bad records
### Process of skipping bad records
## Local execution
